# nlp-models
These are my reimplementations of various NLP models using [PyTorch](https://pytorch.org/)+[torchtext](https://github.com/pytorch/text). Not all of them have been trained.

## Embeddings
- Mikolov, et al., 2013. "Efficient Estimation of Word Representations in Vector Space". ([source code](embeddings/word2vec.ipynb))
- Pennington, et al., 2014. "GloVe: Global Vectors for Word Representation". ([source code](embeddings/glove.ipynb))

## Language Models
- Bengio, et al., 2003. "A Neural Probablistic Language Model". ([source code](language_models/bengio_2003.ipynb))

## Translation
- Sutskever, et al., 2014. "Sequence to Sequence Learning with Neural Networks". ([source code](translation/seq2seq.ipynb))
- Bahdanau, et al., 2014. "Neural Machine Translation by Jointly Learning to Align and Translate". ([source code](translation/seq2seq_attention.ipynb))
- Vaswani, et al., 2017. "Attention Is All You Need". (work in progress, [source code](translation/transformer.ipynb))
